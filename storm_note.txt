##########################################################################
########## 知识技术
##########################################################################
##### 快速把一个javaBean转为json
com.google.gson.Gson

##### 设置开机启动
vi /etc/rc.local 在里面加上命令即可

##### idea快捷键
Ctrl+Shift+先上键  光标所在的行往上移
Ctrl+X 删除行
Shift+回车      在光标所在的行，往下添加一个空白行并把光标定位在新行中。
Shift+Ctrl+回车     自动结束本行，加分号，格式化本行，交把光标定位在行尾。
Ctrl+D 复制行
Alt+ Up/Down 在方法间快速移动光标定位
Ctrl+Shift+Up/Down   整块代码向上/下移动。
选中文本，按Alt+F3 ，逐个往下查找相同文本，并高亮显示。
Ctrl+Alt+t 选择代码块 try catch或if或while
Ctrl+Left/Right移动光标到前/后单词，
Ctrl+[   ]移动到前/后代码块

Shift+Command+Enter  补全当前行，并在行末加上分号。
alt + Command + L   格式化代码
Ctrl + Alt + O   优化导入的包和类
Command + Shift + U  大小写转换
alt + command + M   把代码块抽取为方法



##########################################################################
########## storm
##########################################################################

#编程模型
Datasource: 外部数据源，一个Strom可以有多个数据源
Spout   接收外部数据源的组件，将外部数据源转化成Storm内部的数据，以Tuple为基本的传输单元 下发给Bolt
Bolt    业务逻辑处理节点，可以有多个，接收Spout发送的数据，或上游bolt发送的数据。根据业务逻辑进行处理，发送给下一个bolt或存储到某种介质上。介质可以是redis和mysql
Tuple   Storm内部中数据传输的基本单元，是一个Tuple对象，对象有个list用来保存数据。
StreamGroup   数据分组策略，hadoop中的hashcode % num，轮询、权重、指定、随机分组
              7种：shuffleGrouping(random),Non Grouping(Random),FieldGrouping(Hash取模，同样的userid射到同一个task中)，Local or ShuffleGrouping本地或随机，优先本地

#并发度
用户指定的一个任务，可以被多个线程执行，并发度的数量等于线程的数量。一个任务的多个线程，会被运行在多个Worker(JVM)上。
有一种类似于平均算法的负载均衡策略，尽可能减少网络IO。与MapReduces的本地运算道理相同(尽量运行在数据节点本地机器上)。


#架构
Nimbus：任务分配
Supervisor：接收任务并启动worker，worker的数量根据端口号来的。
Worker：执行任务的具体组件，其实就是一个JVM，可以执行两种类型的任务，Spout任务或bolt任务。
Task：Task=线程=executor。一个属于一个spout或Bolt并发任务。
Zookeeper：保存任务分配信息和心跳信息，元数据信息

#worker与topology
一个worker只属于一个topology，反之，一个topology包含多个worker，其实就是这个topology运行在多个worker上，每个worker中运行的task只能属于这个topology。
一个topology要求的worker数量如果不被满足，集群在任务分配时，根据现有的worker先运行topology。如果当前集群中worker数量为0，那么最新提交的topology将会被标识为active，不会运行，只有当集群有了空闲资源后，才会运行。

##### 自己的理解：
topology相当于hadoop里的MapReduces。Storm程序就叫 Topology。一个Topology的数据是自己独有的，和其他的Topology没啥关系。
说白了，topology就是用来执行我们写的storm程序代码的。
默认情况下：executor数 = thread数 = task数


#概念
Rebalance  把hadoop集群各个机器上的数据进行均匀分布操作，如原有100台机器，数据都在那些上，新上100台，那100台没东西，不均匀，执行此操作，会把东西拿点到100台新机器上。
           把storm里的worker任务进行均匀分布。

#如何指定驱动类中每个组件的并发度数量？也就是wordcount里那几个数字2，4，2
1、根据上游的数据量来设置Spout的并发度
2、根据业务复杂度和execute方法执行时间来设置Bolt并发度
3、根据集群的可用资源来配置，一般情况下70%的资源使用率。
4、worker的数量根据程序并发度总的Task数量来均分。在实际业务场景中，需反复调整。



############## 环境搭建：
压缩包：apache-storm-0.9.5.tar.gz (下载地址https://archive.apache.org/dist/storm/apache-storm-0.9.5/apache-storm-0.9.5.tar.gz)

# 实时计算的目录都在 /export/servers里。离线计算是在/home/hadoop/apps里
su - root
mkdir -p /export/servers
mkdir -p /export/logs
chown -R hadoop:hadoop /export
su - hadoop


cd /home/hadoop
tar -vxzf soft/apache-storm-0.9.5.tar.gz -C /export/servers/
cd /export/servers/
ln -s apache-storm-0.9.5 storm

#修改配置文件
mv /export/servers/storm/conf/storm.yaml /export/servers/storm/conf/storm.yaml.bak
touch /export/servers/storm/conf/storm.yaml
# 修改配置文件storm.yaml
cat >> /export/servers/storm/conf/storm.yaml << EOF
#指定storm使用的zk集群
storm.zookeeper.servers:
     - "s1"
     - "s2"
#指定storm本地状态保存地址
storm.local.dir: "/export/data/storm/workdir"
#指定storm集群中的nimbus节点所在的服务器
nimbus.host: "s1"
#指定nimbus启动JVM最大可用内存大小
nimbus.childopts: "-Xmx1024m"
#指定supervisor启动JVM最大可用内存大小
supervisor.childopts: "-Xmx1024m"
#指定supervisor节点上，每个worker启动JVM最大可用内存大小
worker.childopts: "-Xmx768m"
#指定ui启动JVM最大可用内存大小，ui服务一般与nimbus同在一个节点上。
ui.childopts: "-Xmx768m"
#指定supervisor节点上，启动worker时对应的端口号，每个端口对应槽，每个槽位对应一个worker
supervisor.slots.ports:
    - 6700
    - 6701
    - 6702
    - 6703
EOF

######分发安装包 (分发之前需要在其他机器上建/export目录)
scp -r /export/servers/apache-storm-0.9.5 s2:/export/servers

#在其他机器上建立软链接
cd /export/servers/
ln -s apache-storm-0.9.5 storm
mkdir -p /export/logs

##### 启动集群(主机器s1)
nohup /export/servers/storm/bin/storm nimbus >/dev/null 2>&1 &
nohup /export/servers/storm/bin/storm ui >/dev/null 2>&1 &
# 其他机器
nohup /export/servers/storm/bin/storm supervisor >/dev/null 2>&1 &

###### 查看集群
http://s1:8080
或者jps查看：
主上会多  24274 nimbus
从(s2机器)上会多这个    18696 supervisor   (起的过程中查看jps的话，是出现config_value，启完了会变成supervisor)

######  写代码执行
本地写代码，可以本地调度，也可以放到集群上。放到集群上是这样的流程：
本地代码打成jar包。传上去。执行：
/export/servers/storm/bin/storm jar /export/servers/bigdata.jar cn.jhsoft.bigdata.storm.wordcount.WordCountTopologMain







#########################################################################
########## kafka
##########################################################################

数据生产者 messageProducer
数据消费者 messagetConsumer
数据保存的进程 broker(经济人)，每台服务器上都有独立的broker进程。
数据目的地(分类，主题)  destination,topic
数据分片   partition 有多个有副本
kafka每秒可以写600M写到硬盘上
如何保证消息全局有序？
消费者负载均衡策略？
kafka如何标记消费状态？
kafka有什么独特的特点？
kafka为什么快？
因为是存在内存中，通过pagecache机制。硬盘上的通过sendfile(sendfile:Linux中的"零拷贝")

##### 安装
cd /home/hadoop/soft
wget http://mirrors.hust.edu.cn/apache/kafka/0.8.2.2/kafka_2.11-0.8.2.2.tgz
tar -zxvf /home/hadoop/soft/kafka_2.11-0.8.2.2.tgz -C /export/servers/
cd /export/servers/
ln -s kafka_2.11-0.8.2.2 kafka
mkdir -p /export/servers/logs

#### 配置文件
cp /export/servers/kafka/config/server.properties /export/servers/kafka/config/server.properties.bak
cat > /export/servers/kafka/config/server.properties << EOF
#broker的全局唯一编号，不能重复
broker.id=0
#用来监听连接的端口，producer或consumer将在此端口建立连接
port=9092
#处理网络请求的线程数量
num.network.threads=3
#用来处理磁盘IO的现成数量
num.io.threads=8
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
#接受套接字的缓冲区大小
socket.receive.buffer.bytes=102400
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
#kafka运行日志存放的路径
log.dirs=/export/servers/logs/kafka
#topic在当前broker上的分片个数
num.partitions=2
#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1
#segment文件保留的最长时间，超时将被删除，7天
log.retention.hours=168
#滚动生成新的segment文件的最大时间
log.roll.hours=168
#zookeeper
zookeeper.connect=s1:2181,s2:2181,s3:2181
zookeeper.connection.timeout.ms=6000
EOF

#### 分发安装包
scp -r /export/servers/kafka_2.11-0.8.2.2 s2:/export/servers
#在别的机器上建立软链接和修改别的机器的配置文件
cd /export/servers/
ln -s kafka_2.11-0.8.2.2 kafka
mkdir -p /export/servers/logs
#修改别的机器的 broker.id，分别为0，1，2，3等
sed -i "/^broker.id=/c\broker.id=1" /export/servers/kafka/config/server.properties
#启动本机和目标机器上的kafka服务
nohup /export/servers/kafka/bin/kafka-server-start.sh  /export/servers/kafka/config/server.properties >/dev/null 2>&1 &

###此时可以用jps看，是否有Kafka 这个。

#### kafka常用命令：
#查看当前服务器中的所有topic
/export/servers/kafka/bin/kafka-topics.sh --list --zookeeper s1:2181
#新建主题topic  [partitions是分区，topic 后面的是主题名字，replication-factor是备份的备份数]
/export/servers/kafka/bin/kafka-topics.sh --create --zookeeper s1:2181 --replication-factor 2 --partitions 4 --topic orderMQ
#删除主题
/export/servers/kafka/bin/kafka-topics.sh --delete --zookeeper s1:2181 --topic orderMQ
#配置下环境变量
#通过shell命令发送消息
kafka-console-producer.sh --broker-list s1:9092 --topic orderMQ
#通过shell消费消息
kafka-console-consumer.sh --zookeeper s2:2181 --from-beginning --topic orderMQ
#查看消费位置
kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper s1:2181 --group orderMQ
#查看某个Topic的详情
kafka-topics.sh --topic orderMQ --describe --zookeeper s1:2181


########################################################################
################## 配置环境变量：
########################################################################
su - root
vi /etc/profile
export KAFKA_HOME=/export/servers/kafka
export PATH=$PATH:$KAFKA_HOME/bin

export STORM_HOME=/export/servers/storm
export PATH=$PATH:$STORM_HOME/bin

export ZK_HOME=/home/hadoop/apps/zookeeper-3.4.5
export PATH=$PATH:$ZK_HOME/bin

export HIVE_HOME=/home/hadoop/apps/hive
export PATH=$PATH:$HIVE_HOME/bin

source /etc/profile

su - hadoop
source /etc/profile

这样后就可以 直接执行 kafka-console-producer.sh xxx 这个了。



###########################################################################################################
####################### 项目：双11，实时计算金额、销量等
###########################################################################################################

一、模拟生产过程：

#修改flume配置文件，让他通过log去到kafka中。
配置文件在 本项目 shell/flume_conf/exe2kafka.conf。复制到/home/hadoop/apps/flume/conf 这个目录中
#创建日志目录
mkdir -p /export/data/flume_sources/log
#启动flume
/home/hadoop/apps/flume/bin/flume-ng agent --conf /home/hadoop/apps/flume/conf --conf-file /home/hadoop/apps/flume/conf/myconf/exe2kafka.conf --name a1 &

#生产日志的shell
执行生产日志的文件    把这拷到服务器执行   shell/flume_conf/createlog.sh
这个shell脚本里会往 /export/data/flume_sources/log 这目录下生成数据。
flume里会感应到，因为他是监控 tail -f  shell生成的日志文件。往kafka生产数据

#消费 可以在s2机器上
kafka-console-consumer.sh --zookeeper s2:2181 --from-beginning --topic orderMq

二、程序实现 storm读取和处理kafka里的数据：
程序在kafka2storm中，这需要maven引入 org.apache.kafka 这个包
注意有个坑，当打包到集群中执行时，如提示log4j此类的错误，是因为各个包引入的log4j有冲突，需要<exclusions>排除一下。
org.apache.storm包里也需要加上<scope>provided</scope>，代表不要把这个打包上去，因为服务器集群环境里已经有。


###### 安装redis
su - root    切换到root帐号

cd /home/hadoop/soft
tar -vxzf redis-3.2.9.tar.gz
cd redis-3.2.9
make
cd src
make install
mkdir -p /usr/local/redis/bin
mkdir -p /usr/local/redis/etc
cp ../redis.conf /usr/local/redis/etc
cp redis-benchmark redis-check-aof redis-cli redis-server /usr/local/redis/bin
#是否在后台执行，yes：后台运行；no：不是后台运行（老版本默认）
sed -i "/^daemonize no/c\daemonize yes" /usr/local/redis/etc/redis.conf
sed -i "/^# requirepass foobared/c\requirepass 123456" /usr/local/redis/etc/redis.conf
sed -i "/^bind 127.0.0.1/c\#bind 127.0.0.1" /usr/local/redis/etc/redis.conf


#启动
/usr/local/bin/redis-server /usr/local/redis/etc/redis.conf

#服务器上用客户端来连接
redis-cli -a 123456 -h 127.0.0.1 -p 6379    (后面的-h和-p都可以省掉)。
输入 ping 看响应的是不是 Pong ,如果是Pong才代表通了。
如果java在操作redis时，出现这样的错误：
(error) MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk.
则在redis-cli里执行下面这句话：即可
config set stop-writes-on-bgsave-error no

#持久化配置，默认是不持久化，如果需要配置，修改 /usr/local/redis/etc/redis.conf 文件，
将   appendonly no   中的no改为yes，默认是no
将   appendfsync everysec    按自己的要求来配，具体appendfsync后面的参数是啥意思，下面列出来了
always 收到命令就立即写入磁盘，性能差，完全持久化。
everysec  每秒强制写入磁盘一次，推荐使用，在性能和持久化上作了折中
no  完全依赖os，性能最好，持久化没保证






##########################################################################
########## scala
##########################################################################
val   是value，值，定义的是常量，不可改变
var   是variable，变量的意思，可以改变
def   定义的是方法
函数不需要def，直接  val fun1 =  (v1:Int)=>v1*100，定义的函数可以赋值给变量，这样就可以把这变量当参数进行传递，去再调别的方法。
map   的意思是将 序列，集合，数组等里面的每一个值进行拿出来处理，这就可以  如对a这个集合处理，a.map(fun1)  这样调用，结果就是对a的每个元素都乘100
想实现上面的效果，也可以这样执行：a.map(_*100)，这就是scala里神奇的下划线_，它就是点位符。

函数变形：
val fun1 =  (v1:Int)=>v1*100
val fun12 =  (v1:Int, v2:String) => {v1+v2}
var fun2 : Int=>String = { x => x.toString}
如果两个参数咋接收？
var fun3 : (Int,String) => (String, Int) = {
    (x, y) => {(y+1, x+1)}
}
空返回值的方法
def testa(str :String) : Unit = { xxx }或者
def testa(str :String) = { xxx }   空返回，实际上返回的是 ()
## 把方法变为函数：：[神奇的下划线]
def mm1(v1:Int, v2:Int) : Int = {v1+v2}
val ff2 = mm1 _     与m1功能完全相同的函数，可以当变量传给别的方法。
